{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471c80da-9221-4f58-8403-2a0fea4f5259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00849e3-3835-4f0a-816f-261429b4960b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overfitting - in this method it trains the data very well but test the data very poor\n",
    "# underfitting - in this method it's train and test the data very poorly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37ab737-e687-40e9-b222-c9ee97a73a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d45338b-8992-4bc5-a4bb-6f336716e698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping\n",
    "# Pruning\n",
    "# Regularization\n",
    "# Ensembling\n",
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08572f8b-cc56-4506-b8a9-36f677ddacbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627a1020-e36e-47f9-92dd-dbeb8b94b34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Underfitting is a scenario in data science where a data model is unable to capture the relationship between the input and output variables accurately, generating a high error rate on both the training set and unseen data. It occurs when a model is too simple, which can be a result of a model needing more training time, more input features, or less regularization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912279b0-ae83-4426-8e9b-812aee80bf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4cbdd8-4907-4e6d-a843-5c511bf6dc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In statistics and machine learning, the biasâ€“variance tradeoff is the property of a model that the variance of the parameter estimated across samples can be reduced by increasing the bias in the estimated parameters.A model with a high bias error underfits data and makes very simplistic assumptions on it. A model with a high variance error overfits the data and learns too much from it. A good model is where both Bias and Variance errors are balanced.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82f197a-f678-4869-b2d8-f034f0f92b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3560097b-026c-45a4-ba3d-1219b2d0a886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can determine whether a predictive model is underfitting or overfitting the training data by looking at the prediction error on the training data and the evaluation data. Your model is underfitting the training data when the model performs poorly on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fc1d5b-c6da-4070-ad89-d9b2c5f852fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbd7416-a079-484b-9833-811775e318fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The term \"variance\" refers to the degree of change that may be expected in the estimation of the target function as a result of using multiple sets of training data. The disparity between the values that were predicted and the values that were actually observed is referred to as bias.\n",
    "# A model with high variance may represent the data set accurately but could lead to overfitting to noisy or otherwise unrepresentative training data. In comparison, a model with high bias may underfit the training data due to a simpler model that overlooks regularities in the data.\n",
    "# Examples of high-bias machine learning algorithms include: Linear Regression, Linear Discriminant Analysis and Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce9109b-71f4-4f1c-b35a-d11428c14d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca84245-4ea0-4351-a620-4980ecfd6f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization is a technique that adds information to a model to prevent the occurrence of overfitting. It is a type of regression that minimizes the coefficient estimates to zero to reduce the capacity (size) of a model. In this context, the reduction of the capacity of a model involves the removal of extra weights.\n",
    "# regualarization techniques -  L1, L2, dropout, early stopping, and data augmentation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
