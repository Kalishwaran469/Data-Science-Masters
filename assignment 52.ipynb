{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78247eba-7b06-4842-8cdb-ff39830ee2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cab386-74d1-4e06-9ee2-4e1ac9a2b2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso is a modification of linear regression, where the model is penalized for the sum of absolute values of the weights. Thus, the absolute values of weight will be (in general) reduced, and many will tend to be zeros.Ridge and Lasso Regression. Lasso Regression is different from ridge regression as it uses absolute coefficient values for normalization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e44f69-e453-4cc4-9c63-ca54aa792393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b8e8a4-06c5-46db-9820-43c61ef64f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The main advantage of a LASSO regression model is that it has the ability to set the coefficients for features it does not consider interesting to zero. This means that the model does some automatic feature selection to decide which features should and should not be included on its own.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b63fab-fc4a-45b3-9b65-940126d8db02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c238cb-c795-484f-9cd9-2f868c3af4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Lasso regression, the regularization penalty can lead to some of the coefficients being shrunk to zero, resulting in a sparse model. The number of non-zero coefficients can be used to evaluate the effectiveness of the regularization and feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb70250-7f16-470c-b05a-9e1f13a74225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2eae46-8296-4fe8-ba35-971604f766ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A tuning parameter (Î»), sometimes called a penalty parameter, controls the strength of the penalty term in ridge regression and lasso regression. It is basically the amount of shrinkage, where data values are shrunk towards a central point, like the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e420959-6a2f-4687-a38f-4c4d0249a7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8ea8fc-6d13-4e7f-abdd-2f9c0d3b060d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ordinary lasso penalty has been extensively used in the framework of linear regression models; however, sufficient results have not been obtained for nonlinear regression models with Gaussian basis functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67e4b83-2a51-4fc0-beea-93ca4486ed34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d439900-b4b8-4d81-9c5f-6bc125d6a276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similar to the lasso regression, ridge regression puts a similar constraint on the coefficients by introducing a penalty factor. However, while lasso regression takes the magnitude of the coefficients, ridge regression takes the square. Ridge regression is also referred to as L2 Regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9c1b40-90e1-4d69-a6ac-4c5d10fa38ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a591b6fa-fbb9-417a-aeb9-e533e324b939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (LASSO) regression, solves the same constrained optimization problem as ridge regression, but uses the L1 norm rather than the L2 norm as a measure of complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd24dc25-acd8-4dc1-b071-8b11f672a691",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64516d9e-c7c5-457c-a9ca-ea609fe9510b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defec8d1-b031-4849-bd60-0100c3659878",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d150c0c3-9bb3-4eb8-b7e7-fb4d53396aff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd1e4fc-b1fb-42d5-b87a-b048ac338c4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
