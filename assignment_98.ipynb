{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n15HmO_DA29C"
      },
      "outputs": [],
      "source": [
        "# Understanding Pooling and Padding in CNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# question 1"
      ],
      "metadata": {
        "id": "9B5EsuX-B6zP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In a convolutional neural network, pooling layers are applied after the convolutional layer. The main purpose of pooling is to reduce the size of feature maps, which in turn makes computation faster because the number of training parameters is reduced."
      ],
      "metadata": {
        "id": "z7D-EvwiA5vH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# question 2"
      ],
      "metadata": {
        "id": "3m-pApg7A5x1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# difference between max pooling and minpooling\n",
        "\n",
        "# In max pooling, the operation retains the maximum value from the portion of the image covered by the filter.Min pooling, on the other hand, retains the minimum value from the portion of the image covered by the filter.\n",
        "# It is a type of pooling operation often used in convolutional neural networks (CNNs) to reduce the spatial dimensions of the input.It is a less common pooling technique compared to max pooling.\n",
        "# Max pooling helps in extracting the most important features, discarding the less significant ones.Min pooling can be used in specific scenarios where the focus is on extracting the least intense features or parts of the image."
      ],
      "metadata": {
        "id": "bH1NinzYA50i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# question 3"
      ],
      "metadata": {
        "id": "8FQK9KZPA53N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In the context of Convolutional Neural Networks (CNNs), padding refers to the technique of adding extra pixels around the boundary of an image. This is done before applying the convolution operation. Padding is crucial in CNNs for several reasons, and its significance can be understood in the following ways:\n",
        "# Preservation of spatial dimensions\n",
        "# Prevention of information loss\n",
        "# Control over the spatial size of the output\n",
        "# Mitigation of boundary effects"
      ],
      "metadata": {
        "id": "pPImTSevDDGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# question 4"
      ],
      "metadata": {
        "id": "uQyZjTbzDDJr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# difference between zero padding and valid padding\n",
        "\n",
        "# Same padding, also known as zero padding, refers to the process of adding the necessary number of zero pixels to the input image so that the spatial dimensions of the output feature map remain the same as the input.Valid padding, on the other hand, means no padding is added to the input image. It only applies the convolution operation to the parts of the input where the filter can fully overlap with the input without running off the edges.\n",
        "# It ensures that the spatial information is preserved throughout the convolutional layers, allowing the output feature map to have the same spatial dimensions as the input.This results in an output feature map with reduced spatial dimensions compared to the input, as the edges are not considered in the convolution operation.\n",
        "# Same padding is often useful when there is a need to keep track of the spatial information and preserve the spatial size of the feature maps during the convolution operation.Valid padding is commonly used when the goal is to reduce the spatial dimensions of the feature maps, especially if the focus is on extracting the most critical features from the input data."
      ],
      "metadata": {
        "id": "83g9kxUsDDNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exploring LeNet"
      ],
      "metadata": {
        "id": "4ZfDKcF1A558"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# question 1"
      ],
      "metadata": {
        "id": "mfNdK4EyA58j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LeNet-5 is a pioneering convolutional neural network designed by Yann LeCun, Leon Bottou, Yoshua Bengio, and Patrick Haffner for handwritten and machine-printed character recognition. It was one of the earliest convolutional neural networks and played a crucial role in the development of modern deep learning models, particularly in the field of computer vision. LeNet-5 was introduced in 1998 and has a relatively simple architecture compared to modern CNNs."
      ],
      "metadata": {
        "id": "ekhKnfyUA5_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# question 2"
      ],
      "metadata": {
        "id": "OCqxunkyA6Bz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The key components of LeNet-5 are as follows:\n",
        "\n",
        "# Input Layer:\n",
        "\n",
        "# The input layer of LeNet-5 accepts grayscale images with a fixed size of 32x32 pixels.\n",
        "\n",
        "# Convolutional Layers:\n",
        "\n",
        "# LeNet-5 consists of two sets of convolutional layers, each followed by a subsampling layer The purpose of the convolutional layers is to extract features from the input images using convolution operations with learnable filters.\n",
        "\n",
        "#Subsampling Layers (Average Pooling Layers):\n",
        "\n",
        "# Subsampling layers in LeNet-5 perform average pooling, reducing the spatial dimensions of the feature maps while retaining important features.These layers help in decreasing the sensitivity of the network to small translations in the input image.\n",
        "\n",
        "# Fully Connected Layers:\n",
        "\n",
        "# LeNet-5 has three fully connected layers. The first two fully connected layers serve as intermediate feature extractors, while the final fully connected layer acts as the classifier.The fully connected layers enable the network to learn complex patterns and correlations between features extracted from the earlier layers.\n",
        "\n",
        "# Activation Functions:\n",
        "\n",
        "# LeNet-5 employs nonlinear activation functions, such as the sigmoid or tanh function, after each layer to introduce nonlinearity into the network.\n",
        "\n",
        "# Output Layer:\n",
        "\n",
        "# The output layer of LeNet-5 uses the softmax activation function for multi-class classification, providing the probabilities for each class label."
      ],
      "metadata": {
        "id": "n71JyFysGfDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# question 3"
      ],
      "metadata": {
        "id": "9f8WqfDEGfGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# advantages\n",
        "\n",
        "# Effective Feature Extraction ,Translation Invariance ,Simplicity ,Early Demonstration of CNN Potential\n",
        "\n",
        "# limitations\n",
        "\n",
        "# Limited Complexity ,Limited Scalability ,Lack of Flexibility ,Performance on Large-Scale Data"
      ],
      "metadata": {
        "id": "wRC6oufjGfJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# question 4"
      ],
      "metadata": {
        "id": "e8NSJCkQKBFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import Conv2D,AveragePooling2D\n",
        "from keras.layers import Dense,Flatten\n",
        "from keras.models import Sequential"
      ],
      "metadata": {
        "id": "m7nybPebKBIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train,y_train),(x_test,y_test)=mnist.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZOHgsyjDKBKz",
        "outputId": "0d37ded1-7ed3-4ef1-896c-9c33dd5b054a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=x_train/255.0\n",
        "x_test=x_test/255.0"
      ],
      "metadata": {
        "id": "UNiKWWi0NkU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train=keras.utils.to_categorical(y_train,10)\n",
        "y_test=keras.utils.to_categorical(y_test,10)"
      ],
      "metadata": {
        "id": "u48502YjODWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(6, kernel_size = (5,5), padding = 'valid', activation='tanh', input_shape = (28,28,1)))\n",
        "model.add(AveragePooling2D(pool_size= (2,2), strides = 2, padding = 'valid'))\n",
        "\n",
        "model.add(Conv2D(16, kernel_size = (5,5), padding = 'valid', activation='tanh'))\n",
        "model.add(AveragePooling2D(pool_size= (2,2), strides = 2, padding = 'valid'))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(120, activation='tanh'))\n",
        "model.add(Dense(84, activation='tanh'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qSSFc9nIGfNo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a257798-7258-48ca-b98e-a0963c63a98a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_10 (Conv2D)          (None, 24, 24, 6)         156       \n",
            "                                                                 \n",
            " average_pooling2d_10 (Aver  (None, 12, 12, 6)         0         \n",
            " agePooling2D)                                                   \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 8, 8, 16)          2416      \n",
            "                                                                 \n",
            " average_pooling2d_11 (Aver  (None, 4, 4, 16)          0         \n",
            " agePooling2D)                                                   \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 120)               30840     \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 84)                10164     \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 44426 (173.54 KB)\n",
            "Trainable params: 44426 (173.54 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=5, verbose=1, validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test)\n",
        "\n",
        "print('Test Loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Jkr6pPu3ND8",
        "outputId": "053afc3d-9f5c-4d59-f0d6-f7d3423c71c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "469/469 [==============================] - 25s 52ms/step - loss: 1.0875 - accuracy: 0.7383 - val_loss: 0.5490 - val_accuracy: 0.8695\n",
            "Epoch 2/5\n",
            "469/469 [==============================] - 24s 51ms/step - loss: 0.4812 - accuracy: 0.8740 - val_loss: 0.3997 - val_accuracy: 0.8948\n",
            "Epoch 3/5\n",
            "469/469 [==============================] - 23s 49ms/step - loss: 0.3856 - accuracy: 0.8932 - val_loss: 0.3392 - val_accuracy: 0.9064\n",
            "Epoch 4/5\n",
            "469/469 [==============================] - 25s 54ms/step - loss: 0.3356 - accuracy: 0.9046 - val_loss: 0.2996 - val_accuracy: 0.9156\n",
            "Epoch 5/5\n",
            "469/469 [==============================] - 24s 51ms/step - loss: 0.3005 - accuracy: 0.9143 - val_loss: 0.2706 - val_accuracy: 0.9226\n",
            "313/313 [==============================] - 2s 6ms/step - loss: 0.2706 - accuracy: 0.9226\n",
            "Test Loss: 0.2705730199813843\n",
            "Test accuracy: 0.9225999712944031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyzing AlexNet"
      ],
      "metadata": {
        "id": "MDYwTR7e4hsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# question 1"
      ],
      "metadata": {
        "id": "XJ4pSWf04h9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AlexNet is a seminal deep learning model that made significant strides in the field of computer vision, particularly in image classification tasks. Developed by Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton, it won the ImageNet Large Scale Visual Recognition Challenge in 2012, and its architecture laid the groundwork for the subsequent development of deep learning models."
      ],
      "metadata": {
        "id": "ZuN11n1P4iKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# question 2"
      ],
      "metadata": {
        "id": "vcznFMTK4idt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# AlexNet introduced several architectural innovations that contributed to its breakthrough performance in the ImageNet Large Scale Visual Recognition Challenge in 2012. These innovations played a crucial role in demonstrating the potential of deep learning for image classification tasks and significantly influenced the subsequent development of deep neural network models. Some of the key architectural innovations introduced in AlexNet include:\n",
        "# Deep Architecture,Rectified Linear Units (ReLU) Activation,Local Response Normalization,Data Augmentation,Dropout Regularization"
      ],
      "metadata": {
        "id": "ubzAC67w4ixi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# question 3"
      ],
      "metadata": {
        "id": "pjz2yQO56MrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convolutional Layers:\n",
        "\n",
        "# AlexNet contains five convolutional layers, each responsible for learning and extracting increasingly complex features from the input images. These layers apply convolution operations to the input data, using learnable filters to detect patterns and features at different levels of abstraction. The depth and breadth of these convolutional layers enabled the network to learn intricate representations of the input images, facilitating improved classification accuracy.\n",
        "\n",
        "# Pooling Layers:\n",
        "\n",
        "# Interspersed between the convolutional layers, AlexNet incorporates max pooling layers to downsample the feature maps, reducing the spatial dimensions and the computational complexity of the network. Pooling helps create a more robust representation of the features extracted by the convolutional layers, making the network less sensitive to variations in the position of the features within the input images.\n",
        "\n",
        "# Fully Connected Layers:\n",
        "\n",
        "# After the convolutional and pooling layers, AlexNet includes three fully connected layers. The first two fully connected layers have 4096 nodes each, while the last fully connected layer has 1000 nodes. These layers act as high-level feature extractors and classifiers, enabling the network to make predictions based on the complex representations learned from the earlier layers. The last fully connected layer uses the softmax activation function to generate a probability distribution over the 1000 ImageNet classes, facilitating the classification of input images into different categories."
      ],
      "metadata": {
        "id": "z_zP9vYz6MuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aYzQp0IKaQ5F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}