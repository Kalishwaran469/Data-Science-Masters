{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668fda32-7dfa-46dc-8c00-425e49aff139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b42e176-e79d-40f7-a7e4-abdbdff98492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boosting is a method used in machine learning to reduce errors in predictive data analysis. Data scientists train machine learning software, called machine learning models, on labeled data to make guesses about unlabeled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb776c8-1a98-4822-82da-29b07b89a5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e1707b-af73-41b8-a160-3a3384f39731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boosting is a resilient method that curbs over-fitting easily. One disadvantage of boosting is that it is sensitive to outliers since every classifier is obliged to fix the errors in the predecessors. Thus, the method is too dependent on outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf4c2f6-17af-4c36-b6db-c9655dd6b029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb3361f-dd10-49ad-a5b5-1b7150e7f558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boosting creates an ensemble model by combining several weak decision trees sequentially. It assigns weights to the output of individual trees. Then it gives incorrect classifications from the first decision tree a higher weight and input to the next tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f704dd8-64d9-4acc-a607-9b801279dc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df693ab5-6c39-4a05-89ba-4b5528f19ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adaboosting\n",
    "# gradient boosting\n",
    "# xg boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183eecb6-c0d3-495a-afbe-f0220e10b780",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0c3c47-2e51-4fec-bc0a-33d7a28b732b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning rate\n",
    "# max_depth\n",
    "# n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f85af3-d3db-40c2-bef4-6628a22265c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed94db53-7bad-4655-8dfc-5d57de599e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boosting is an ensemble learning method that combines a set of weak learners into a strong learner to minimize training errors. In boosting, a random sample of data is selected, fitted with a model and then trained sequentially—that is, each model tries to compensate for the weaknesses of its predecessor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9e7a0f-f608-4566-a1b1-95c2470f50f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52ab9dc-3e02-42f8-8be8-7607e8c05804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It makes ‘n’ number of decision trees during the data training period. As the first decision tree/model is made, the incorrectly classified record in the first model is given priority. Only these records are sent as input for the second model. The process goes on until we specify a number of base learners we want to create. Remember, repetition of records is allowed with all boosting techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf4995f-575a-4c8a-a1d8-e508b074c8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7b754d-749e-4c6f-8944-de0a8b28eb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The error function that AdaBoost uses is an exponential loss function. First we find the products between the true values of training samples and the overall prediction for each sample. Then we take the sum of all the exponentials of these products in order to compute the error at iteration m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da61ece2-f402-401b-aea8-7cdc09ed43bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a09750-c2b2-44fd-9a08-34b80fb54070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initially all the data points have equal probability of getting selected, that is each data point has a weight equal to 1/N. In each iteration the weight of a data point gets changed in such a way, that it gets decreased, if it is correctly classified by the model generated in that iteration and increased otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583e1343-8f20-486d-af8c-214b80e78379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b46a6e4-54e3-4a88-af28-9537b411a102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The learning rate depends highly upon the number of n_estimators. By default, it is set to 1 but it can be increased or decreased depending on the estimators used. Generally, for a large number of n_estimators, we use a smaller value of learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0ae795-a134-4dbd-b555-d69aa962085a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5979e846-3b97-4445-bcea-7cbc38729d18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f16387b-a44f-4458-9ea9-348487123c51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfb296d-2ffb-463b-9918-dde77e8e62e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
