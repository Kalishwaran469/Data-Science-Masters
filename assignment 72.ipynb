{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3313f9f-d0f9-44bb-ae11-98a36cb4d4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0995fbff-c378-46e5-96a5-2698dca1a7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Nearest Neighbors Algorithm. The k-nearest neighbors algorithm, also known as KNN or k-NN, is a non-parametric, supervised learning classifier, which uses proximity to make classifications or predictions about the grouping of an individual data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0caad97-30fe-4033-8390-e8139728a96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0b4a54-f908-4749-a731-281a7eb60515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The choice of k will largely depend on the input data as data with more outliers or noise will likely perform better with higher values of k. Overall, it is recommended to have an odd number for k to avoid ties in classification, and cross-validation tactics can help you choose the optimal k for your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91886315-291a-4134-9571-a313be775202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25ed7b3-8b9e-489e-a329-874f7c4a92c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The key differences are: KNN regression tries to predict the value of the output variable by using a local average. KNN classification attempts to predict the class to which the output variable belong by computing the local probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512c0612-5c75-4a39-b4b3-acb8042a25b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aea1f81-bb76-497e-8d9a-020de61be0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of nearest neighbours (K values).\n",
    "# Compute the distance between test sample and all the training samples.\n",
    "# Sort the distance and determine nearest neighbours based on the K-th minimum distance.\n",
    "# Assemble the categories of the nearest neighbours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3b4bb2-5621-4df9-a293-c8c4720f1766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee3b834-1255-463f-982b-d7212f8648b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The “Curse of Dimensionality” is a tongue in cheek way of stating that there's a ton of space in high-dimensional data sets. The size of the data space grows exponentially with the number of dimensions. This means that the size of your data set must also grow exponentially in order to keep the same density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cada0b57-c7c8-4030-ba16-cf891407488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d206028c-26e3-470b-a4f2-d29f378fc172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNNimputer is a scikit-learn class used to fill out or predict the missing values in a dataset. It is a more useful method which works on the basic approach of the KNN algorithm rather than the naive approach of filling all the values with mean or the median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de537db5-8374-4b91-a275-91d2f7475694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7072ada2-471a-4d02-8994-ccfc9aa03f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn classifier is suitabke for classification problems on the other side knn regressor is suitable for regression problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84848a82-d86e-45f6-8725-6a7d6a101e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5d8c28-4ff2-45a6-aee4-fb27b74a8958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# advantages - The KNN algorithm is well-known for its simplicity and has several key strengths, including: Zero training time: KNN requires very little training time compared to other machine learning algorithms.\n",
    "# disadvantages - Here are some of the disadvantages of using the k-nearest neighbors algorithm: Associated computation cost is high as it stores all the training data. Requires high memory storage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfa1769-9de1-4067-910a-54223d962bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2d7b22-ccce-4add-8e17-aff0b57e5cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euclidean distance is the shortest path between source and destination which is a straight line but Manhattan distance is sum of all the real distances between source(s) and destination(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f710174-61b6-4c2e-b751-a44d2ade6fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced07c50-e4f5-4d99-9580-6b959132c24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling is essential for machine learning algorithms that calculate distances between data. If not scaled, the feature with a higher value range starts dominating when calculating distances. KNN which uses Euclidean distance is one such algorithm which essentially require scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c991ba34-7da4-44e2-a871-8882ded43778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a387fed-88c2-40ba-bb3f-6359cf95356a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
