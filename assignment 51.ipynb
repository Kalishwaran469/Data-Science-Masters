{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27fb17d-fc85-452d-96d2-eb21aa40b8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80eea3f2-8574-4ee8-bbf7-f6e1bb1b5040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge regression is a term used to refer to a linear regression model whose coefficients are estimated not by ordinary least squares (OLS), but by an estimator, called ridge estimator, that, albeit biased, has lower variance than the OLS estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d83ed88-0300-47d7-99a2-5441aebcc20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7ef0be-8808-4be4-b4a8-3ae00501156f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The assumptions of ridge regression are the same as that of linear regression: linearity, constant variance, and independence. However, as ridge regression does not provide confidence limits, the distribution of errors to be normal need not be assumed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a72838e-3e12-4a4d-8ba6-5b840a7f5227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31af07fe-740b-4b9a-a5aa-648aff47c314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting a good value for λ is critical. When λ=0, the penalty term has no effect, and ridge regression will produce the classical least square coefficients. However, as λ increases to infinite, the impact of the shrinkage penalty grows, and the ridge regression coefficients will get close zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af88fe60-df59-496d-b5eb-4db273b94d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ac95ed-6922-4b4c-8f02-342c89e7cb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use ridge regression for feature selection while fitting the model.use logistic regression for model fitting and push the parameter penalty as L2 which basically means the penalty we use in ridge regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d584a5-7206-4a8f-b468-fec4b6bc47d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec69a3ce-df41-404f-82a6-d177e80472ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When multicollinearity occurs, least squares estimates are unbiased, but their variances are large so they may be far from the true value. By adding a degree of bias to the regression estimates, ridge regression reduces the standard errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a189f3-79f3-4a4f-b993-3d060ba1c1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedcea54-4ae1-4d92-8178-141cb04d738a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge regression is used for regression purpose only as it needs the dependent variable to be continuous. So for your analysis Ridge regression can't be used. Special characteristic of Ridge regression is it works fine in presence of multicollinearity but with a continuous dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ab760f-1538-487c-906f-d0ddbdf785d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38533270-4180-4aee-8cc6-398fc7997e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ridge coefficients are a reduced factor of the simple linear regression coefficients and thus never attain zero values but very small values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2745987-e5ef-4971-bb7b-8bf77adfb149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8754ed99-e8ae-4ef7-b881-30d571ffa58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ridge regression technique can be used to predict time-series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b9ddf5-90e0-47c1-9e91-adf1bafdf8d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9759a2cc-f6d4-46b0-915c-0fb5c090151c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
