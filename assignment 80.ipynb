{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22da3954-f9ea-406f-bc9c-af6024d5a835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f797cd-47e6-48c8-8e9f-abae53f2fe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierarchical clustering is a popular method for grouping objects. It creates groups so that objects within a group are similar to each other and different from objects in other groups. Clusters are visually represented in a hierarchical tree called a dendrogram.Hierarchical Clustering involves creating clusters in a predefined order from top to bottom . Non Hierarchical Clustering involves formation of new clusters by merging or splitting the clusters instead of following a hierarchical order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734205d2-cb22-465d-903b-9c9abc9658be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b2745d-8860-48fd-88d6-13489649dc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agglomerative: Agglomerative is a bottom-up approach, in which the algorithm starts with taking all data points as single clusters and merging them until one cluster is left. Divisive: Divisive algorithm is the reverse of the agglomerative algorithm as it is a top-down approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d82d7a6-f0e3-4e51-ad3b-c1b6558ffd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab1d7cf-521c-4529-82b4-724a1d06ea8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For most common hierarchical clustering software, the default distance measure is the Euclidean distance. This is the square root of the sum of the square differences. However, for gene expression, correlation distance is often used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9745724e-0fe8-4685-97e6-af1d110f892d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ef32ea-e4dc-4cba-bf26-005cce9474a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the optimal number of clusters for hierarchical clustering, we make use a dendrogram which is tree-like chart that shows the sequences of merges or splits of clusters. If two clusters are merged, the dendrogram will join them in a graph and the height of the join will be the distance between those clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ce0d4b-b97c-43d1-be62-44d8796c9bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c5662e-5a5c-4377-9244-80ef7fd5099b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dendrogram is a very useful technique in hierarchical clustering method to find the optimal number of cluster value.it is a tree like web chart in this technique first every datapoint forms a cluster then near cluster points forms a another cluster group this process is going until we get a single cluster group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3974daed-c15f-4b2a-b792-aa268886c255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2417cd02-48e9-43a1-8804-fa22bd208a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most distance metrics, and hence the hierarchical clustering methods, work either with continuous-only or categorical-only data. In applications, however, observations are often described by a combination of both continuous and categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3172b72f-ae65-42af-9ff5-7a63402947b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd88283a-f48d-4acf-899e-0603ecb0f9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case of hierarchical clustering, by using dendrogram outliers are found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f15c22-1f79-4e71-85e4-aae52754e714",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9e4577-8b9d-4501-a1a5-4b24704ea91e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4993df96-25c6-491c-808b-26c5b94e8129",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
